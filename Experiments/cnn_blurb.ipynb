{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blurb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMCRcsJftUIj",
        "colab_type": "code",
        "outputId": "c102323d-db29-48cc-e84f-80206b770592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import pandas as pd\n",
        "# import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import os\n",
        "from sqlalchemy import create_engine # database connection\n",
        "import datetime as dt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdsUGLq3KLD0",
        "colab_type": "code",
        "outputId": "6ad8c47a-ea1f-4ce2-dd7b-fc68f3d73b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn.datasets as skds\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Haw4L1T7FQx9",
        "colab_type": "code",
        "outputId": "c4359303-5a30-4b98-f6b1-f61bdc50e700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df=pd.read_csv('./blurb_ml.csv')\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 77109 rows and 4 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HQcuXKIGWFY",
        "colab_type": "code",
        "outputId": "ca76511d-edf0-4643-a3ce-3be3233da41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "df.Genres=df.Genres.apply(lambda x: json.loads(x))\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Name</th>\n",
              "      <th>Genres</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Teenage Mutant Ninja Turtles: The Box Set Volu...</td>\n",
              "      <td>[Graphic Novels and Manga, Fiction]</td>\n",
              "      <td>TMNT co-creator Kevin Eastman and writer Tom W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Betty and Veronica: Fairy Tales</td>\n",
              "      <td>[Children’s Middle Grade Books, Children’s Books]</td>\n",
              "      <td>Take a magical trip down Storybook Lane with t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Friends and Fauxs</td>\n",
              "      <td>[Women’s Fiction, Fiction]</td>\n",
              "      <td>Tracie Howard is back with all of the Gucci, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Anti-Education</td>\n",
              "      <td>[Philosophy, Religion and Philosophy, Nonfiction]</td>\n",
              "      <td>AN NYRB Classics OriginalIn 1869, at the age o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Fallout</td>\n",
              "      <td>[Espionage Mysteries, Mystery and Suspense, Fi...</td>\n",
              "      <td>A first-class letter–containing a single sheet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77104</th>\n",
              "      <td>77104</td>\n",
              "      <td>Design and Crime (And Other Diatribes)</td>\n",
              "      <td>[Art, Politics, Nonfiction]</td>\n",
              "      <td>In these diatribes on the marketing of culture...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77105</th>\n",
              "      <td>77105</td>\n",
              "      <td>The Things We Cherished</td>\n",
              "      <td>[Historical Romance, Literary Fiction, Fiction]</td>\n",
              "      <td>Charlotte Gold is shocked when her ex-fiancé B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77106</th>\n",
              "      <td>77106</td>\n",
              "      <td>National Geographic Traveler: Madrid, 2nd Edition</td>\n",
              "      <td>[Travel: Europe, Travel, Nonfiction]</td>\n",
              "      <td>All the travel experts agreeconsumers want mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77107</th>\n",
              "      <td>77107</td>\n",
              "      <td>Hate Crime</td>\n",
              "      <td>[Nonfiction]</td>\n",
              "      <td>On June 7, 1998, James Byrd Jr., a forty-nine-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77108</th>\n",
              "      <td>77108</td>\n",
              "      <td>How to Sharpen Pencils</td>\n",
              "      <td>[Humor]</td>\n",
              "      <td>A hilarious guide to the lost art of artisanal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77109 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                            Summary\n",
              "0               0  ...  TMNT co-creator Kevin Eastman and writer Tom W...\n",
              "1               1  ...  Take a magical trip down Storybook Lane with t...\n",
              "2               2  ...  Tracie Howard is back with all of the Gucci, g...\n",
              "3               3  ...  AN NYRB Classics OriginalIn 1869, at the age o...\n",
              "4               4  ...  A first-class letter–containing a single sheet...\n",
              "...           ...  ...                                                ...\n",
              "77104       77104  ...  In these diatribes on the marketing of culture...\n",
              "77105       77105  ...  Charlotte Gold is shocked when her ex-fiancé B...\n",
              "77106       77106  ...  All the travel experts agreeconsumers want mo...\n",
              "77107       77107  ...  On June 7, 1998, James Byrd Jr., a forty-nine-...\n",
              "77108       77108  ...  A hilarious guide to the lost art of artisanal...\n",
              "\n",
              "[77109 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOWdpuc-GV9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etz5GLCoLJau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_RXDZkeLJTQ",
        "colab_type": "code",
        "outputId": "067cd178-da48-4dab-f632-5f5ee899bc6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXF7ieIc3owA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop=True)\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHgNwf5q3zON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Summary'] = df['Summary'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-jm5L2GNVyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HclxeNSRTSqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gdd(x):\n",
        "    a=x.split()\n",
        "    return len(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXIhPpKXTSnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEkdJOarTSjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXMMrpYgTSh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "preprocessed_synopsis = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in df['Summary'].values:\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = decontracted(sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "    preprocessed_synopsis.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTQblLG1TSci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['preprocessed_plots']=preprocessed_synopsis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CKcysHfT3Yf",
        "colab_type": "code",
        "outputId": "3974ed15-e0ad-4644-fc26-3c0dd0c66ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Name', 'Genres', 'Summary', 'preprocessed_plots'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOVnjIkT5Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def remove_spaces(x):\n",
        "    \n",
        "    return (\",\").join(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZEL0lruT5Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df['Genres']=df['Genres'].apply(remove_spaces)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16VyrXTpT5Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test = train_test_split(df, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxN0j6lKT5B7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\",\"), binary='true')\n",
        "y_train = vectorizer.fit_transform(train['Genres']).toarray()\n",
        "y_test=vectorizer.transform(test['Genres']).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydqmOwUVJ9e",
        "colab_type": "code",
        "outputId": "2daec892-77dc-498a-f6fc-cb0ec38a87b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(df['Summary'].apply(gdd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LuOs1x7VZit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect=Tokenizer()\n",
        "vect.fit_on_texts(train['Summary'])\n",
        "vocab_size = len(vect.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCv31RqeZefx",
        "colab_type": "code",
        "outputId": "66a35415-e11d-4ef7-ca06-111bfbb24fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291212"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2c6xOvAVfvy",
        "colab_type": "code",
        "outputId": "57fabdea-605a-494f-de40-203cde83c950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "encoded_docs_train = vect.texts_to_sequences(train['preprocessed_plots'])\n",
        "max_length = vocab_size\n",
        "padded_docs_train = sequence.pad_sequences(encoded_docs_train, maxlen=1200, padding='post')\n",
        "print(padded_docs_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   835   3888   8389 ...      0      0      0]\n",
            " [    59    176    174 ...      0      0      0]\n",
            " [105888   4958   2140 ...      0      0      0]\n",
            " ...\n",
            " [    92   2747  56004 ...      0      0      0]\n",
            " [  1118   3993     96 ...      0      0      0]\n",
            " [  6349    126   8384 ...      0      0      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HymCKNlVl8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_docs_test = vect.texts_to_sequences(test['preprocessed_plots'])\n",
        "padded_docs_test = sequence.pad_sequences(encoded_docs_test, maxlen=1200, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wNCI4VKVv-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1micro(y_true, y_pred):\n",
        "    return tf.py_func(f1_score(y_true, y_pred,average='mirco'),tf.double)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY4p2QipVzMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, Conv2D, MaxPooling1D, Dropout, Activation,GlobalMaxPool1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from time import time\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkyktaikV1Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1micro', verbose=0, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clggm4IAV4Fb",
        "colab_type": "code",
        "outputId": "632e021c-3fb3-4cfb-9921-7d573b4ea8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1micro', verbose=0, save_best_only=True, mode='max')\n",
        "model = Sequential()\n",
        "# model.add(Embedding(max_words, 20, input_length=maxlen))\n",
        "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(140, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1200, 50)          0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 140)               7140      \n",
            "=================================================================\n",
            "Total params: 13,013,990\n",
            "Trainable params: 13,013,990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wQXu9YKV6ms",
        "colab_type": "code",
        "outputId": "87c976f4-88b6-486b-c7cc-2946b46b6352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-simple1.hdf5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(padded_docs_train, y_train,\n",
        "                    class_weight='balanced',\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55518 samples, validate on 6169 samples\n",
            "Epoch 1/3\n",
            "55518/55518 [==============================] - 194s 3ms/step - loss: 0.1023 - val_loss: 0.0627\n",
            "Epoch 2/3\n",
            "55518/55518 [==============================] - 193s 3ms/step - loss: 0.0560 - val_loss: 0.0540\n",
            "Epoch 3/3\n",
            "55518/55518 [==============================] - 181s 3ms/step - loss: 0.0502 - val_loss: 0.0496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwTAnaVXV-x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5BWglPCWOHU",
        "colab_type": "code",
        "outputId": "8959044f-b7e9-4edb-f6f3-f6160c30c545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "for val in thresholds:\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro-average quality numbers\n",
            "Precision: 0.2892, Recall: 0.6319, F1-measure: 0.3968\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5081, Recall: 0.4834, F1-measure: 0.4955\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6509, Recall: 0.4071, F1-measure: 0.5009\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7494, Recall: 0.3522, F1-measure: 0.4792\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8101, Recall: 0.3052, F1-measure: 0.4433\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8556, Recall: 0.2616, F1-measure: 0.4007\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8919, Recall: 0.2151, F1-measure: 0.3466\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9224, Recall: 0.1634, F1-measure: 0.2777\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9564, Recall: 0.0956, F1-measure: 0.1739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndRQtmNJY6Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlMxb-OqY6Vc",
        "colab_type": "code",
        "outputId": "f2bd2f72-2428-4ba1-8b83-4248f9b5dbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1micro', verbose=0, save_best_only=True, mode='max')\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 71, input_length=1200))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(300, 3, activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "# model.add(Conv1D(200, 3, activation='relu'))\n",
        "# model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(140))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()\n",
        "model.fit(padded_docs_train, y_train,\n",
        "          class_weight='balanced',\n",
        "          epochs=3,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2)\n",
        "predictions=model.predict(padded_docs_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 1200, 71)          18469727  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1200, 71)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1198, 300)         64200     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 140)               42140     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 140)               0         \n",
            "=================================================================\n",
            "Total params: 18,576,067\n",
            "Trainable params: 18,576,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 49349 samples, validate on 12338 samples\n",
            "Epoch 1/3\n",
            "49349/49349 [==============================] - 542s 11ms/step - loss: 0.0611 - val_loss: 0.0537\n",
            "Epoch 2/3\n",
            "49349/49349 [==============================] - 537s 11ms/step - loss: 0.0422 - val_loss: 0.0491\n",
            "Epoch 3/3\n",
            "49349/49349 [==============================] - 530s 11ms/step - loss: 0.0363 - val_loss: 0.0506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlU1Lpa9Y6Rn",
        "colab_type": "code",
        "outputId": "41caa535-6b86-4347-8431-3476d6dffd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.1734, Recall: 0.8858, F1-measure: 0.2901\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.2880, Recall: 0.8046, F1-measure: 0.4241\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.3913, Recall: 0.7416, F1-measure: 0.5123\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.4862, Recall: 0.6822, F1-measure: 0.5678\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5779, Recall: 0.6276, F1-measure: 0.6017\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6668, Recall: 0.5755, F1-measure: 0.6178\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7527, Recall: 0.5178, F1-measure: 0.6136\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8359, Recall: 0.4507, F1-measure: 0.5856\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9121, Recall: 0.3577, F1-measure: 0.5139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe_uKTFQY5w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvfHXZZ1ZR0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes=140"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMrTQzcEZW-f",
        "colab_type": "code",
        "outputId": "b2e1046f-3553-42f6-d1b6-425db2c79ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1micro', verbose=0, save_best_only=True, mode='max')\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "# model.add(LSTM(6119, input_shape=(timesteps, input_dim)))\n",
        "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
        "model.add(LSTM(128))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               91648     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 140)               18060     \n",
            "=================================================================\n",
            "Total params: 13,116,558\n",
            "Trainable params: 13,116,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Rpn_DlZZ2D",
        "colab_type": "code",
        "outputId": "9842c6b1-e798-47aa-812e-ca7f1ba2f269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "# callbacks = [\n",
        "#     ReduceLROnPlateau(),\n",
        "#     EarlyStopping(patience=4),\n",
        "#     ModelCheckpoint(filepath='model-2.h5', save_best_only=True)\n",
        "# ]\n",
        "history = model.fit(padded_docs_train, y_train,\n",
        "                    class_weight='balanced',\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               91648     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 140)               18060     \n",
            "=================================================================\n",
            "Total params: 13,116,558\n",
            "Trainable params: 13,116,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55518 samples, validate on 6169 samples\n",
            "Epoch 1/3\n",
            "55518/55518 [==============================] - 2290s 41ms/step - loss: 0.0728 - val_loss: 0.0636\n",
            "Epoch 2/3\n",
            "55518/55518 [==============================] - 2330s 42ms/step - loss: 0.0649 - val_loss: 0.0637\n",
            "Epoch 3/3\n",
            "55518/55518 [==============================] - 2349s 42ms/step - loss: 0.0646 - val_loss: 0.0635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtTJjbKTZt6k",
        "colab_type": "code",
        "outputId": "73883067-be7a-457e-b3b7-86f2d83fac4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.2996, Recall: 0.3774, F1-measure: 0.3340\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.2996, Recall: 0.3774, F1-measure: 0.3340\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.3423, Recall: 0.2875, F1-measure: 0.3125\n",
            "For threshold:  0.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we0erqKoZt3J",
        "colab_type": "code",
        "outputId": "ca9a65a7-e010-4968-a629-f4d8df5b943c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1micro', verbose=0, save_best_only=True, mode='max')\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "# model.add(LSTM(6119, input_shape=(timesteps, input_dim)))\n",
        "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
        "# model.add(LSTM(128))\n",
        "model.add(LSTM(128, return_sequences=True))  \n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history = model.fit(padded_docs_train, y_train,\n",
        "                    class_weight='balanced',\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1200, 128)         91648     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1200, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 140)               9100      \n",
            "=================================================================\n",
            "Total params: 13,157,006\n",
            "Trainable params: 13,157,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55518 samples, validate on 6169 samples\n",
            "Epoch 1/3\n",
            "55518/55518 [==============================] - 3691s 66ms/step - loss: 0.0763 - val_loss: 0.0637\n",
            "Epoch 2/3\n",
            "55518/55518 [==============================] - 3631s 65ms/step - loss: 0.0655 - val_loss: 0.0637\n",
            "Epoch 3/3\n",
            "55518/55518 [==============================] - 3598s 65ms/step - loss: 0.0652 - val_loss: 0.0636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc3TOG18ZtzI",
        "colab_type": "code",
        "outputId": "d41ace67-9b94-4216-86a8-d17e3c42d428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.2996, Recall: 0.3774, F1-measure: 0.3340\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.2996, Recall: 0.3774, F1-measure: 0.3340\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.3423, Recall: 0.2875, F1-measure: 0.3125\n",
            "For threshold:  0.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOTQJ0NtZtvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val=0.2\n",
        "pred=predictions.copy()\n",
        "pred[pred>=val]=1\n",
        "pred[pred<val]=0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGUBtoMNr3pR",
        "colab_type": "code",
        "outputId": "9600fd35-b3f6-4ce0-e61d-d38d8ec7ca4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "vectorizer.inverse_transform(pred[1000]),vectorizer.inverse_transform(y_test[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array(['children’s books', 'fiction', 'nonfiction'], dtype='<U51')],\n",
              " [array(['cooking', 'cooking methods', 'nonfiction'], dtype='<U51')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Qb8phNr3Zd",
        "colab_type": "code",
        "outputId": "d7225c3a-5e7a-43da-f23f-b549bec5bc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3934,  222,  406, ...,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKNORf_oZtpu",
        "colab_type": "code",
        "outputId": "4508d88f-9cf8-413f-9112-8a0f7b55940d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
        "# model.add(layers.Embedding(vocab_size, embedding_dim,  \n",
        "#                            input_length=1200, \n",
        "#                            trainable=True))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(100, activation='sigmoid'))\n",
        "# classifier.add(Dropout(.70))\n",
        "\n",
        "model.add(layers.Dense(n_classes, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "                  optimizer='adam')\n",
        "\n",
        "model.fit(padded_docs_train, y_train,\n",
        "                        epochs=2,\n",
        "                        verbose=False,\n",
        "                        validation_data=(padded_docs_test, y_test),\n",
        "                        batch_size=16)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 140)               14140     \n",
            "=================================================================\n",
            "Total params: 13,026,090\n",
            "Trainable params: 13,026,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5bb07caf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka3cyvnMZvet",
        "colab_type": "code",
        "outputId": "479125f9-cd1b-4ce2-d6fc-82fb8862b14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.3682, Recall: 0.6407, F1-measure: 0.4676\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5765, Recall: 0.5255, F1-measure: 0.5498\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7045, Recall: 0.4635, F1-measure: 0.5591\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7866, Recall: 0.4181, F1-measure: 0.5459\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8339, Recall: 0.3780, F1-measure: 0.5202\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8712, Recall: 0.3378, F1-measure: 0.4868\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9020, Recall: 0.2965, F1-measure: 0.4463\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9296, Recall: 0.2505, F1-measure: 0.3946\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9597, Recall: 0.1814, F1-measure: 0.3051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKudtr7UZvbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhkEqfhDZxnZ",
        "colab_type": "code",
        "outputId": "64f18e10-e1ba-4205-a140-d86b3539fe84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=50, input_length=1200))\n",
        "# model.add(layers.Embedding(vocab_size, embedding_dim,  \n",
        "#                            input_length=1200, \n",
        "#                            trainable=True))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(100, activation='sigmoid'))\n",
        "model.add(Dropout(.70))\n",
        "model.add(layers.Dense(100, activation='sigmoid'))\n",
        "model.add(layers.Dense(n_classes, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy')\n",
        "model.summary()\n",
        "model.fit(padded_docs_train, y_train,\n",
        "                        epochs=5,\n",
        "                        verbose=False,\n",
        "                        validation_data=(padded_docs_test, y_test),\n",
        "                        batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 1200, 50)          13006850  \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 140)               14140     \n",
            "=================================================================\n",
            "Total params: 13,036,190\n",
            "Trainable params: 13,036,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f5bb0ac0908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83frdeN7ZxjP",
        "colab_type": "code",
        "outputId": "af978931-abea-465e-9241-7b6ad73cdb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.3599, Recall: 0.6773, F1-measure: 0.4700\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.5629, Recall: 0.5613, F1-measure: 0.5621\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.6958, Recall: 0.4912, F1-measure: 0.5759\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.7823, Recall: 0.4391, F1-measure: 0.5625\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8384, Recall: 0.3962, F1-measure: 0.5381\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.8766, Recall: 0.3596, F1-measure: 0.5100\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9079, Recall: 0.3228, F1-measure: 0.4763\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9282, Recall: 0.2897, F1-measure: 0.4416\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.9526, Recall: 0.2332, F1-measure: 0.3747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Di98DThZxca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes=140"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KijUa2BIaP7O",
        "colab_type": "code",
        "outputId": "01140ddc-4401-4bd5-bbef-e737d14269a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
        "model.add(Embedding(vocab_size, 71, input_length=1200))\n",
        "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
        "# model.add(Dropout(0.70))\n",
        "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
        "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
        "model.add(Conv1D(48, 3, activation='sigmoid'))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dense(n_classes))\n",
        "# model.add(Dropout(0.70))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
        "model.summary()\n",
        "history=model.fit(padded_docs_train, y_train,\n",
        "                        epochs=5,\n",
        "                        verbose=False,\n",
        "                        validation_split=0.1,\n",
        "                        batch_size=16,\n",
        "                  callbacks=[])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1200, 71)          20676052  \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 1198, 64)          13696     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 1196, 100)         19300     \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 1194, 100)         30100     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 1192, 48)          14448     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 57216)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 140)               8010380   \n",
            "=================================================================\n",
            "Total params: 28,763,976\n",
            "Trainable params: 28,763,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ2Q9LwAaPzd",
        "colab_type": "code",
        "outputId": "4131dacb-a806-4f64-93a9-888861793653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0100, Recall: 0.0377, F1-measure: 0.0158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT110KcTapRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwR4z08sapNM",
        "colab_type": "code",
        "outputId": "dc8908fb-5d54-49e1-ee03-278d6837f287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
        "model.add(Embedding(vocab_size, 71, input_length=1200))\n",
        "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
        "model.add(Dropout(0.70))\n",
        "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
        "model.add(Dropout(0.70))\n",
        "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
        "model.add(Dropout(0.70))\n",
        "model.add(Conv1D(48, 3, activation='sigmoid'))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(6, activation='softmax'))\n",
        "model.add(Dense(n_classes))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
        "model.summary()\n",
        "model.fit(padded_docs_train, y_train,\n",
        "                        epochs=10,\n",
        "                        verbose=False,\n",
        "                        validation_split=0.1,\n",
        "                        batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 1200, 71)          20676052  \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 1198, 64)          13696     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1198, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 1196, 100)         19300     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1196, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 1194, 100)         30100     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1194, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 1192, 48)          14448     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 57216)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 140)               8010380   \n",
            "=================================================================\n",
            "Total params: 28,763,976\n",
            "Trainable params: 28,763,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f51409c9f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9cQHJxDapFH",
        "colab_type": "code",
        "outputId": "591cba4b-7a54-4c50-ad2d-b9a672bd6155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "predictions=model.predict([padded_docs_test])\n",
        "for val in thresholds:\n",
        "    print(\"For threshold: \", val)\n",
        "    pred=predictions.copy()\n",
        "  \n",
        "    pred[pred>=val]=1\n",
        "    pred[pred<val]=0\n",
        "  \n",
        "    precision = precision_score(y_test, pred, average='micro')\n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    f1 = f1_score(y_test, pred, average='micro')\n",
        "   \n",
        "    print(\"Micro-average quality numbers\")\n",
        "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For threshold:  0.1\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.2\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.3\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.4\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.5\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.6\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.7\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.8\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n",
            "For threshold:  0.9\n",
            "Micro-average quality numbers\n",
            "Precision: 0.0875, Recall: 0.1838, F1-measure: 0.1186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaVSNPcJao8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvgIeClNaozf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}