{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP example(ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "import csv\n",
    "import tf_idf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing functions\n",
    "def remove_stopwords(data):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = word_tokenize(str(data))\n",
    "    \n",
    "    filtered_data = \"\"\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and len(w)>1:\n",
    "            filtered_data=filtered_data+\" \"+w\n",
    "    return filtered_data\n",
    "    \n",
    "def remove_punctuation(data):\n",
    "    marks=\"~!@#$%^&*()_+=-`[]\\;'./{}|:<>?\"\"'\\n\"\n",
    "    \n",
    "    for i in marks:\n",
    "        data=np.char.replace(data,i,' ')\n",
    "        data=np.char.replace(data,\"  \",\" \")\n",
    "    \n",
    "    data=np.char.replace(data,\",\",'')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    \n",
    "    new_text = \"\"\n",
    "    \n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "def lemmatize(data):\n",
    "    wnl=WordNetLemmatizer()\n",
    "    tokens = word_tokenize(str(data))\n",
    "    \n",
    "    new_text = \"\"\n",
    "    \n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + wnl.lemmatize(w)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        \n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "\n",
    "def preprocess(data):\n",
    "    for i in range(len(data))\n",
    "        data[i]=np.char.lower(data)\n",
    "    \n",
    "        data[i] = remove_punctuation(data) #remove comma seperately\n",
    "    \n",
    "        data[i] = remove_apostrophe(data)\n",
    "    \n",
    "        data[i] = remove_stopwords(data)\n",
    "    \n",
    "        data[i] = convert_numbers(data)\n",
    "    \n",
    "        data[i] = stemming(data)\n",
    "    \n",
    "        data[i] = remove_punctuation(data)\n",
    "        data[i] = convert_numbers(data)\n",
    "        data[i] = stemming(data) #needed again as we need to stem the words\n",
    "        data[i] = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "        data[i] = remove_stopwords(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(remove_punctuation(\"hey! how are you? i have 3 colors: red, white, and yellow.\"))\n",
    "\n",
    "# print(lemmatize(\"hey! how are you lying i? have 3 studies colors: red, white, and yellow.\"))\n",
    "# print(PorterStemmer().stem(\"study\"))\n",
    "\n",
    "# print(convert_numbers(\"hii 1002\"))\n",
    "# file = open('D:\\\\SDP/stories/SRE/sre01.txt', 'r', encoding=\"utf8\", errors='ignore')\n",
    "# text = file.read().strip()\n",
    "# file.close()\n",
    "#print(preprocess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF_IDF calculation for a bunch of documents present in the stories folder, idf is calculated by considering one story as a document\n",
    "index.html contains list of all stories and their titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#extracting all folders\n",
    "folders=[x[0] for x in os.walk(str(os.getcwd())+'/stories/')]\n",
    "folders=folders[1:]\n",
    "#print(folders)\n",
    "\n",
    "#extracting name and title of each story\n",
    "dataset=[]\n",
    "for f in folders:\n",
    "    file=open(f+'/index.html','r')\n",
    "    text=file.read().strip()\n",
    "    file.close()\n",
    "    \n",
    "    names=re.findall('><A HREF=\"(.*)\">',text)\n",
    "    titles=re.findall('<BR><TD> (.*)\\n', text)\n",
    "    for j in range(len(names)):\n",
    "        dataset.append((str(f)+'/'+names[j],titles[j]))\n",
    "#print(dataset)\n",
    "\n",
    "N=len(dataset)\n",
    "#extracting data\n",
    "processed_text = []\n",
    "processed_title = []\n",
    "\n",
    "for i in dataset[:N]:\n",
    "    file = open(i[0], 'r', encoding=\"utf8\", errors='ignore')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    #preprocess and append whole file i.e. story\n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n",
    "    \n",
    "    #preprocess and append title i.e. in i[1]..dataset(filename,title)\n",
    "    processed_title.append(word_tokenize(str(preprocess(i[1]))))\n",
    "\n",
    "\n",
    "#calculate df for all words    \n",
    "DF = {}\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])\n",
    "# print(\"DF\",DF)\n",
    "\n",
    "\n",
    "doc = 0\n",
    "\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_text[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_title[i])\n",
    "    words_count = len(tokens + processed_title[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = 0\n",
    "        try:\n",
    "            df=DF[token]\n",
    "        except:\n",
    "            pass\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025662985945743163\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf[0,\"alway\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with our dataset, booksummaries.txt containing all the book titles and their summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "dataset1=[]\n",
    "dataset=[]\n",
    "#dataset1: the whole dataset\n",
    "#dataset: minimized version containing 3 books\n",
    "#0:wikipediaId 1:fiebaseId 2:name 3:author 4:publish date 5:genres 6:summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\SDP/repo/book_summarization/booksummaries.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "    reader=csv.reader(f,dialect='excel-tab')\n",
    "    for row in reader:\n",
    "        dataset1.append([row[0],row[2],row[3],row[4],row[5],row[6]])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\SDP/repo/book_summarization/booksummaries1.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "    reader=csv.reader(f,dialect='excel-tab')\n",
    "    for row in reader:\n",
    "        dataset.append([row[0],row[2],row[3],row[4],row[5],row[6]])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset=dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dataset,columns=['ID','Name','Author','Date','Genres','Summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                       Name           Author  \\\n",
       "0   620                                Animal Farm    George Orwell   \n",
       "1   843                         A Clockwork Orange  Anthony Burgess   \n",
       "2   986                                 The Plague     Albert Camus   \n",
       "3  1756  An Enquiry Concerning Human Understanding       David Hume   \n",
       "4  2080                       A Fire Upon the Deep     Vernor Vinge   \n",
       "\n",
       "         Date                                             Genres  \\\n",
       "0  1945-08-17  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1        1962  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2        1947  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                                  \n",
       "4              {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             Summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...\n",
       "1    {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...\n",
       "2    {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...\n",
       "3                                                     \n",
       "4    {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...\n",
       "Name: Genres, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                  Name           Author        Date  \\\n",
       "0   620           Animal Farm    George Orwell  1945-08-17   \n",
       "1   843    A Clockwork Orange  Anthony Burgess        1962   \n",
       "2   986            The Plague     Albert Camus        1947   \n",
       "4  2080  A Fire Upon the Deep     Vernor Vinge               \n",
       "\n",
       "                                              Genres  \\\n",
       "0  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "4  {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             Summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(df[df['Genres']==''].index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genres']=df['Genres'].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'/m/016lj8': 'Roman à clef',\n",
       " '/m/06nbt': 'Satire',\n",
       " '/m/0dwly': \"Children's literature\",\n",
       " '/m/014dfn': 'Speculative fiction',\n",
       " '/m/02xlf': 'Fiction',\n",
       " '/m/06n90': 'Science Fiction',\n",
       " '/m/0l67h': 'Novella',\n",
       " '/m/0c082': 'Utopian and dystopian fiction',\n",
       " '/m/02m4t': 'Existentialism',\n",
       " '/m/0pym5': 'Absurdist fiction',\n",
       " '/m/05hgj': 'Novel',\n",
       " '/m/03lrw': 'Hard science fiction',\n",
       " '/m/01hmnh': 'Fantasy'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres={}\n",
    "\n",
    "print(len(df['Genres']))\n",
    "for i in df['Genres']:\n",
    "    for i1,j1 in i.items():\n",
    "        try:\n",
    "            genres[i1]=j1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summaryfeatures=[]\n",
    "summaryfeatures=df['Summary'].apply(lambda x: tf_idf.generate_features(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaryfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/m/016lj8': ['uniting',\n",
       "  'workhorse',\n",
       "  'special',\n",
       "  'thin',\n",
       "  'working',\n",
       "  'worlds',\n",
       "  'tell',\n",
       "  'upright',\n",
       "  'violent',\n",
       "  'work'],\n",
       " '/m/06nbt': ['uniting',\n",
       "  'workhorse',\n",
       "  'special',\n",
       "  'thin',\n",
       "  'working',\n",
       "  'worlds',\n",
       "  'tell',\n",
       "  'upright',\n",
       "  'violent',\n",
       "  'work',\n",
       "  'window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence'],\n",
       " '/m/0dwly': ['uniting',\n",
       "  'workhorse',\n",
       "  'special',\n",
       "  'thin',\n",
       "  'working',\n",
       "  'worlds',\n",
       "  'tell',\n",
       "  'upright',\n",
       "  'violent',\n",
       "  'work'],\n",
       " '/m/014dfn': ['uniting',\n",
       "  'workhorse',\n",
       "  'special',\n",
       "  'thin',\n",
       "  'working',\n",
       "  'worlds',\n",
       "  'tell',\n",
       "  'upright',\n",
       "  'violent',\n",
       "  'work',\n",
       "  'window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence',\n",
       "  'unthinking',\n",
       "  'two',\n",
       "  'years',\n",
       "  'war',\n",
       "  'technology',\n",
       "  'universe',\n",
       "  'young',\n",
       "  'world',\n",
       "  'wrecking',\n",
       "  'unharmed'],\n",
       " '/m/02xlf': ['uniting',\n",
       "  'workhorse',\n",
       "  'special',\n",
       "  'thin',\n",
       "  'working',\n",
       "  'worlds',\n",
       "  'tell',\n",
       "  'upright',\n",
       "  'violent',\n",
       "  'work',\n",
       "  'window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence',\n",
       "  'violence',\n",
       "  'test',\n",
       "  'well',\n",
       "  'view',\n",
       "  'ward',\n",
       "  'unexpected',\n",
       "  'use',\n",
       "  'would',\n",
       "  'waste',\n",
       "  'unaware',\n",
       "  'unthinking',\n",
       "  'two',\n",
       "  'years',\n",
       "  'war',\n",
       "  'technology',\n",
       "  'universe',\n",
       "  'young',\n",
       "  'world',\n",
       "  'wrecking',\n",
       "  'unharmed'],\n",
       " '/m/06n90': ['window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence',\n",
       "  'unthinking',\n",
       "  'two',\n",
       "  'years',\n",
       "  'war',\n",
       "  'technology',\n",
       "  'universe',\n",
       "  'young',\n",
       "  'world',\n",
       "  'wrecking',\n",
       "  'unharmed'],\n",
       " '/m/0l67h': ['window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence'],\n",
       " '/m/0c082': ['window',\n",
       "  'young',\n",
       "  'walloping',\n",
       "  'unintended',\n",
       "  'working',\n",
       "  'wife',\n",
       "  'tragic',\n",
       "  'unconscious',\n",
       "  'violent',\n",
       "  'violence'],\n",
       " '/m/02m4t': ['violence',\n",
       "  'test',\n",
       "  'well',\n",
       "  'view',\n",
       "  'ward',\n",
       "  'unexpected',\n",
       "  'use',\n",
       "  'would',\n",
       "  'waste',\n",
       "  'unaware'],\n",
       " '/m/0pym5': ['violence',\n",
       "  'test',\n",
       "  'well',\n",
       "  'view',\n",
       "  'ward',\n",
       "  'unexpected',\n",
       "  'use',\n",
       "  'would',\n",
       "  'waste',\n",
       "  'unaware'],\n",
       " '/m/05hgj': ['violence',\n",
       "  'test',\n",
       "  'well',\n",
       "  'view',\n",
       "  'ward',\n",
       "  'unexpected',\n",
       "  'use',\n",
       "  'would',\n",
       "  'waste',\n",
       "  'unaware'],\n",
       " '/m/03lrw': ['unthinking',\n",
       "  'two',\n",
       "  'years',\n",
       "  'war',\n",
       "  'technology',\n",
       "  'universe',\n",
       "  'young',\n",
       "  'world',\n",
       "  'wrecking',\n",
       "  'unharmed'],\n",
       " '/m/01hmnh': ['unthinking',\n",
       "  'two',\n",
       "  'years',\n",
       "  'war',\n",
       "  'technology',\n",
       "  'universe',\n",
       "  'young',\n",
       "  'world',\n",
       "  'wrecking',\n",
       "  'unharmed']}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genrefeatures={}\n",
    "for x in summaryfeatures.keys():\n",
    "    for i,j in df.loc[x]['Genres'].items():\n",
    "        try:\n",
    "            genrefeatures[i]=genrefeatures[i]+summaryfeatures[x]\n",
    "        except:\n",
    "            genrefeatures[i]=summaryfeatures[x]\n",
    "genrefeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access features of any genre, use the genre ID from 'genres' as the key in genrefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uniting',\n",
       " 'workhorse',\n",
       " 'special',\n",
       " 'thin',\n",
       " 'working',\n",
       " 'worlds',\n",
       " 'tell',\n",
       " 'upright',\n",
       " 'violent',\n",
       " 'work',\n",
       " 'window',\n",
       " 'young',\n",
       " 'walloping',\n",
       " 'unintended',\n",
       " 'working',\n",
       " 'wife',\n",
       " 'tragic',\n",
       " 'unconscious',\n",
       " 'violent',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'test',\n",
       " 'well',\n",
       " 'view',\n",
       " 'ward',\n",
       " 'unexpected',\n",
       " 'use',\n",
       " 'would',\n",
       " 'waste',\n",
       " 'unaware',\n",
       " 'unthinking',\n",
       " 'two',\n",
       " 'years',\n",
       " 'war',\n",
       " 'technology',\n",
       " 'universe',\n",
       " 'young',\n",
       " 'world',\n",
       " 'wrecking',\n",
       " 'unharmed']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genrefeatures['/m/02xlf']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ignore all code from here onwards, still left to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The novel posits that space around the Milky Way is divided into concentric layers called Zones, each being constrained by different laws of physics and each allowing for different degrees of biological and technological advancement. The innermost, the \"Unthinking Depths\", surrounds the galactic core and is incapable of supporting advanced life forms at all. The next layer, the \"Slow Zone\", is roughly equivalent to the real world in behavior and potential. Further out, the zone named the \"Beyond\" can support futuristic technologies such as AI and FTL travel. The outermost zone, the \"Transcend\", contains most of the galactic halo and is populated by incomprehensibly vast and powerful posthuman entities. A human expedition investigates a five-billion-year-old data archive that offers the possibility of unimaginable riches for the ambitious young civilization of the Straumli Realm. The expedition\\'s facility, called High Lab, is gradually compromised by a dormant super-intelligent entity (actually encoded within the archive) later known as the Blight. The Blight rapidly learns how to infiltrate and control the computer systems of High Lab, and even develops the ability to possess and control the living humans. The novel starts with an imaginative description of the evolution of this superintelligence through exponentially accelerating developmental stages, culminating in a transcendent, nigh-omnipotent power that is unfathomable to mere humans. Shortly before its final \"flowering\", the changes in a single minute of the Blight\\'s life are said to exceed those of 10,000 years of human civilization. Recognizing the danger of what they have awakened, the researchers at High Lab attempt to flee in two ships. Suspicious, the Blight discovers that one of the ships contains a data storage device in its cargo manifest; assuming it contains information that could harm it, the Blight destroys the ship. The second ship is allowed to escape, unharmed, as the Blight assumes that it is no threat; but later realizes that it actually held a countermeasure, one of the few things in the universe that the Blight fears. The ship lands on a distant planet with a medieval-level civilization of dog-like creatures dubbed \"Tines\", who live in packs as group minds. The ship is revealed to be a sleeper ship, carrying most of High Lab\\'s children in \"coldsleep boxes\". The boxes are rapidly failing and the surviving adults begin unloading them, but are killed when one of two rival forces of Tines seize the ship. The faction that initially contacts the humans, led by a Tine known as Steel, kills the adults and destroys many of the coldsleep boxes. They also capture a boy named Jefri Olsndot, whom Steel intended on killing but eventually exploits in order to develop advanced technology (such as cannon and radio communication). Jefri\\'s older sister, Johanna, is rescued by Pilgrim and Scriber, wandering Tines who bring her to the rival faction, led by Woodcarver. She is asked to help develop technology that could gain the upper hand in the impending war. A distress signal from the sleeper ship eventually reaches \"Relay\", a major node in the galactic communications network. A benign transcendent entity (known as a \"Power\") named \"Old One\" contacts Relay, seeking information about the Blight and the humans who released it. Old One constructs a seemingly human man, Pham Nuwen, to act as its agent. Pham and Ravna Bergsndot – a human employee of Relay\\'s owners, the wealthy Vrinimi Organization – trace the sleeper ship\\'s signal to the Tines world. Old One designs a vessel, the Out of Band II, to reach the Tines world and to investigate what the ship carried with it from the High Lab. The Blight attacks Relay and Old One. Old One gives Pham the information necessary to activate the Blight Countermeasure while dying (a process known as godshatter), and Pham and Ravna escape Relay\\'s destruction in the Out of Band II. After arriving at the Tines homeworld and allying with Woodcarver to defeat Steel, Pham initiates the Countermeasure, which extends the Slow Zone by thousands of light-years to enclose the Blight. This ends the threat of the Blight at the cost of wrecking thousands of uninvolved civilizations, causing trillions of deaths and potentially the extinction of several galactic races. The process also kills Pham and strands the other humans on the Tines world, now in the depths of the \"Slow Zone\" where rescue by an advanced civilization is impossible.'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary='The novel posits that space around the Milky Way is divided into concentric layers called Zones, each being constrained by different laws of physics and each allowing for different degrees of biological and technological advancement. The innermost, the \"Unthinking Depths\", surrounds the galactic core and is incapable of supporting advanced life forms at all. The next layer, the \"Slow Zone\", is roughly equivalent to the real world in behavior and potential. Further out, the zone named the \"Beyond\" can support futuristic technologies such as AI and FTL travel. The outermost zone, the \"Transcend\", contains most of the galactic halo and is populated by incomprehensibly vast and powerful posthuman entities. A human expedition investigates a five-billion-year-old data archive that offers the possibility of unimaginable riches for the ambitious young civilization of the Straumli Realm. The expedition\\'s facility, called High Lab, is gradually compromised by a dormant super-intelligent entity (actually encoded within the archive) later known as the Blight. The Blight rapidly learns how to infiltrate and control the computer systems of High Lab, and even develops the ability to possess and control the living humans. The novel starts with an imaginative description of the evolution of this superintelligence through exponentially accelerating developmental stages, culminating in a transcendent, nigh-omnipotent power that is unfathomable to mere humans. Shortly before its final \"flowering\", the changes in a single minute of the Blight\\'s life are said to exceed those of 10,000 years of human civilization. Recognizing the danger of what they have awakened, the researchers at High Lab attempt to flee in two ships. Suspicious, the Blight discovers that one of the ships contains a data storage device in its cargo manifest; assuming it contains information that could harm it, the Blight destroys the ship. The second ship is allowed to escape, unharmed, as the Blight assumes that it is no threat; but later realizes that it actually held a countermeasure, one of the few things in the universe that the Blight fears. The ship lands on a distant planet with a medieval-level civilization of dog-like creatures dubbed \"Tines\", who live in packs as group minds. The ship is revealed to be a sleeper ship, carrying most of High Lab\\'s children in \"coldsleep boxes\". The boxes are rapidly failing and the surviving adults begin unloading them, but are killed when one of two rival forces of Tines seize the ship. The faction that initially contacts the humans, led by a Tine known as Steel, kills the adults and destroys many of the coldsleep boxes. They also capture a boy named Jefri Olsndot, whom Steel intended on killing but eventually exploits in order to develop advanced technology (such as cannon and radio communication). Jefri\\'s older sister, Johanna, is rescued by Pilgrim and Scriber, wandering Tines who bring her to the rival faction, led by Woodcarver. She is asked to help develop technology that could gain the upper hand in the impending war. A distress signal from the sleeper ship eventually reaches \"Relay\", a major node in the galactic communications network. A benign transcendent entity (known as a \"Power\") named \"Old One\" contacts Relay, seeking information about the Blight and the humans who released it. Old One constructs a seemingly human man, Pham Nuwen, to act as its agent. Pham and Ravna Bergsndot – a human employee of Relay\\'s owners, the wealthy Vrinimi Organization – trace the sleeper ship\\'s signal to the Tines world. Old One designs a vessel, the Out of Band II, to reach the Tines world and to investigate what the ship carried with it from the High Lab. The Blight attacks Relay and Old One. Old One gives Pham the information necessary to activate the Blight Countermeasure while dying (a process known as godshatter), and Pham and Ravna escape Relay\\'s destruction in the Out of Band II. After arriving at the Tines homeworld and allying with Woodcarver to defeat Steel, Pham initiates the Countermeasure, which extends the Slow Zone by thousands of light-years to enclose the Blight. This ends the threat of the Blight at the cost of wrecking thousands of uninvolved civilizations, causing trillions of deaths and potentially the extinction of several galactic races. The process also kills Pham and strands the other humans on the Tines world, now in the depths of the \"Slow Zone\" where rescue by an advanced civilization is impossible.'\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' novel posit space around milki way divid concentr layer call zone constrain differ law physic allow differ degr biolog technolog advanc innermost unthink depth surround galact core incap support advanc life form next layer slow zone roughli equiv real world behavior potenti zone name beyond support futurist technolog ai ftl travel outermost zone transcend contain galact halo popul incomprehen vast power posthuman entiti human expedit investig five billion year old data archiv offer possibl unimagin rich ambiti young civil straumli realm expedit facil call high lab gradual compromi dormant super intellig entiti actual encod within archiv later known blight blight rapidli learn infiltr control comput system high lab even develop abil possess control live human novel start imagin descript evolut superintellig exponenti accel develop stage culmin transcend nigh omnipot power unfathom mere human shortli final flower chang singl minut blight life said exceed ten thousand year human civil recogn danger awaken research high lab attempt flee two ship suspici blight discov one ship contain data storag devic cargo manifest assum contain inform could harm blight destroy ship second ship allow escap unharm blight assum threat later realiz actual held countermeasur one thing univ blight fear ship land distant planet mediev level civil dog like creatur dub tine live pack group mind ship reveal sleeper ship carri high lab children coldsleep box box rapidli fail surviv adult begin unload kill one two rival forc tine seiz ship faction initi contact human led tine known steel kill adult destroy mani coldsleep box also captur boy name jefri olsndot steel intend kill eventu exploit order develop advanc technolog cannon radio commun jefri older sister johanna rescu pilgrim scriber wander tine bring rival faction led woodcarv ask help develop technolog could gain upper hand impend war distress signal sleeper ship eventu reach relay major node galact commun network benign transcend entiti known power name old one contact relay seek inform blight human relea old one construct seemingli human man pham nuwen act agent pham ravna bergsndot human employ relay owner wealthi vrinimi organ trace sleeper ship signal tine world old one design vessel band ii reach tine world investig ship carri high lab blight attack relay old one old one give pham inform necessari activ blight countermeasur die process known godshatt pham ravna escap relay destruct band ii arriv tine homeworld alli woodcarv defeat steel pham initi countermeasur extend slow zone thousand light year enclo blight end threat blight cost wreck thousand uninvolv civil cau trillion death potenti extinct sever galact race process also kill pham strand human tine world depth slow zone rescu advanc civil imposs'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags=list(genres.values())\n",
    "# tags=df.Genres.apply(lambda x: list(x.keys())[0])\n",
    "\n",
    "X=df.Summary\n",
    "Y=list(df.Genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roman à clef',\n",
       " 'Satire',\n",
       " \"Children's literature\",\n",
       " 'Speculative fiction',\n",
       " 'Fiction',\n",
       " 'Science Fiction',\n",
       " 'Novella',\n",
       " 'Utopian and dystopian fiction',\n",
       " 'Existentialism',\n",
       " 'Absurdist fiction',\n",
       " 'Novel',\n",
       " 'Hard science fiction',\n",
       " 'Fantasy']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Old Major, the old boar on the Manor Farm, ca...\n",
       "1     Alex, a teenager living in near-future Englan...\n",
       "2     The text of The Plague is divided into five p...\n",
       "4     The novel posits that space around the Milky ...\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/016lj8', '/m/06n90', '/m/02m4t', '/m/03lrw']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Old Major, the old boar on the Manor Farm, ca...\n",
       "2     The text of The Plague is divided into five p...\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Alex, a teenager living in near-future Englan...\n",
       "4     The novel posits that space around the Milky ...\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/016lj8', '/m/02m4t']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/06n90', '/m/03lrw']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Comic       0.00      0.00      0.00       0.0\n",
      "     Fiction       0.00      0.00      0.00       1.0\n",
      "         abc       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "Wall time: 12.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ghata\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\ghata\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(Y_pred, Y_test))\n",
    "print(classification_report(Y_test, Y_pred,target_names=['Comic','Fiction','abc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/m/02m4t', '/m/02m4t'], dtype='<U9')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
